{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a41fec-c7f0-4752-b57a-efb428327343",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d51c63-ed05-43d4-9e02-7d13763b5011",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of different data loaders in `tgml`. The job of a data loader is to pull data from the TigerGraph database. Currently, the following data loaders are provided:\n",
    "* EdgeLoader, which returns either the whole edgelist or batches of edges. Edge attributes are not supported currently.\n",
    "* VertexLoader, which returns either all the vertices or batches of vertices. Vertex attributes are supported.\n",
    "* GraphLoader, which returns the whole graph in `PyG` format.\n",
    "* NeighborLoader, which returns subgraphs using neighbor sampling.\n",
    "\n",
    "Every data loader above can either stream data directly from the server to user or cache data on the cloud. For the latter, data will be moved to a cloud storage first and then downloaded to local, so it will be slower compared to streaming directly from the server. However, when there are multiple consumers of the same data such as when trying out different models in parallel or tuning hyperparameters, the cloud caching would reduce workload of the server, and consequently it might be faster than hitting the server from multiple consumers at the same time. \n",
    "\n",
    "Note: For the data loaders to work, the [Graph Data Processing Service](https://github.com/TigerGraph-DevLabs/GDPS) has to be running on the TigerGraph server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9243a4-69ae-4a04-ab82-dc6d393e0cb7",
   "metadata": {},
   "source": [
    "### Define Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff08e15-5d93-4f30-8a9d-6b101b1604e4",
   "metadata": {},
   "source": [
    "Conceptually, the `TigerGraph` class represents the graph stored in the database. Under the hood, it stores the necessary information to communicate with the TigerGraph database. It can read `username` and `password` from environment variables `TGUSERNAME` and `TGPASSWORD`. Hence, we recommend storing those credentials in the environment variables or in a `.env` file instead of hardcoding them in code. However, if you do provide `username` and `password` to this class constructor, the environment variables will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e2237-5050-4c58-91de-c86b804d19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgml.data import TigerGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d970f31-2ab8-4fd5-86bf-1067814bb949",
   "metadata": {
    "tags": []
   },
   "source": [
    "Args to the `TigerGraph` class:\n",
    "*    host (str, ): Address of the server. Defaults to \"http://localhost\".\n",
    "*    graph (str, ): Name of the graph. Defaults to None.\n",
    "*    username (str, optional): Username. Defaults to None.\n",
    "*    password (str, optional): Password for the user. Defaults to None.\n",
    "*    rest_port (str, optional): Port for the REST endpoint. Defaults to \"9000\".\n",
    "*    gs_port (str, optional): Port for GraphStudio. Defaults to \"14240\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c4b1e8-a0e2-4026-9bb1-218cdc7ca4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgraph = TigerGraph(host = \"http://35.230.92.92\",\n",
    "                    graph = \"Cora\",\n",
    "                    username = \"tigergraph\",\n",
    "                    password = \"tigergraphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d512ecf9-cf0f-4bb6-b5fe-376be158c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgraph.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd0252-a5e5-47ee-acce-b843571c78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgraph.number_of_vertices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd27069-0ef7-4fe5-8060-55632e2f4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgraph.number_of_vertices(\"Paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b7836-91a1-49ed-b8f3-d6608d9718b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgraph.number_of_vertices(filter_by = \"train_mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f1998-1179-4ae2-9f1b-d1b032076c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgraph.number_of_vertices(vertex_type = \"Paper\", filter_by = \"train_mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ebe58-e9c3-4e54-b1ae-fb17e49755ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgraph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457342b-0626-4b7e-8b9b-0cc0c38c9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgraph.number_of_edges(\"Cite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f29ef-6b65-4999-9363-f9dfde5e478c",
   "metadata": {},
   "source": [
    "### Edge Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bdb697-d286-4f2d-8c34-b6c05dc89be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgml.dataloaders import EdgeLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141a8d2-2a4d-4ced-b4ab-17b5e7604994",
   "metadata": {},
   "source": [
    "For the first time you initialize the loader on a graph in TigerGraph, the initialization might take a minute as it installs the corresponding query to the database and optimizes it. However, the query installation only needs to be done once, so it will take no time when you initialize the loader on the same TG graph again.  \n",
    "\n",
    "There are two ways to use the data loader. \n",
    "* First, it can be used as an iterator, which means you can loop through it to get every batch of data. If you load all edges at once, there will be only one batch (of all the edges) in the iterator. \n",
    "* Second, you can access the `data` property of the class directly. If there is only one batch of data to load, it will give you the batch directly instead of an iterator, which might make more sense in that case. If there are multiple batches of data to load, it will return the iterator again. \n",
    "\n",
    "Args to `EdgeLoader` class:\n",
    "* graph (TigerGraph): Connection to the TigerGraph database.\n",
    "* batch_size (int, optional): Size of each batch. If given, `num_batches` will be recalculated based on batch size. Defaults to None.\n",
    "* num_batches (int, optional): Number of batches to split the whole dataset. Defaults to 1.\n",
    "* local_storage_path (str, optional): Place to store data locally. Defaults to \"./tmp\".\n",
    "* cloud_storage_path (str, optional): S3 path used for cloud caching. Defaults to None.\n",
    "* buffer_size (int, optional): Number of data batches to prefetch and store in memory. Defaults to 4.\n",
    "* output_format (str, optional): Format of the output data of the loader. Defaults to \"dataframe\".\n",
    "* aws_access_key_id (str, optional): AWS access key. Defaults to None.\n",
    "* aws_secret_access_key (str, optional): AWS access key secret. Defaults to None.\n",
    "\n",
    "If using cloud caching, cloud storage access keys need to be provided. For AWS s3, `aws_access_key_id` and `aws_secret_access_key` are required. However, the class can read from environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`, and again it is recommended to store those credentials in the `.env` file instead of hardcoding them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a985e-2686-496a-8d5b-7f413ebf435a",
   "metadata": {},
   "source": [
    "#### Load all edges at once directly to local. Default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03830f8-07c9-4d94-b7bd-5489ec7104cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "edge_loader = EdgeLoader(tgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221850f0-24d7-4f1b-b733-dd6d3fd639fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Use case 1: iterator\n",
    "data = []\n",
    "for batch in edge_loader:\n",
    "    data.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6d656-5729-4656-96df-bb562cc011b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef47555-b7b3-4db4-abd6-a9f17f1538f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Use case 2: `data` property\n",
    "data = edge_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75e404-ed20-47dd-830d-8eea8c9e82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad44dea5-d5ba-495d-9ca5-2f968f0c8ae5",
   "metadata": {},
   "source": [
    "#### Stream batches of edges directly to local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecea0bdb-f2d2-4efe-b7cf-e46493f76edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "edge_loader = EdgeLoader(tgraph, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae37fd-f451-48de-ae02-375d10d18fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Use case 1: as an iterator\n",
    "data = []\n",
    "for batch in edge_loader:\n",
    "    data.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704fcc32-53d5-4b20-917a-46fbb6cde489",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of batches: \", len(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245319f8-fc90-404e-9ff3-fa5911e5ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case 2: `data` property\n",
    "# Since there are multiple batches of data. \n",
    "# The `data` property will return the loader itsel\n",
    "data = edge_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0339c-b27b-49cd-927d-03049a4e346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Number of batches: \", sum(1 for batch in data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2cc34-545d-4220-8938-e3eda1797fda",
   "metadata": {},
   "source": [
    "### Vertex Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb86e8-1f31-450f-bd3d-f2e20a3a234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgml.dataloaders import VertexLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490831c-409e-4234-9c7c-775273ca698b",
   "metadata": {},
   "source": [
    "For the first time you initialize the loader on a graph in TigerGraph, the initialization might take half a minute as it installs the corresponding query to the database and optimizes it. However, the query installation only needs to be done once, so it will take no time when you initialize the loader on the same TG graph again.  \n",
    "\n",
    "There are two ways to use the data loader. \n",
    "* First, it can be used as an iterator, which means you can loop through it to get every batch of data. If you load all vertices at once, there will be only one batch of data (of all the vertices) in the iterator. \n",
    "* Second, you can access the `data` property of the class directly. If there is only one batch of data, it will give you the batch directly instead of an iterator, which might make more sense in that case. If there are multiple batches of data to load, it will return the loader again.\n",
    "\n",
    "Args to class:\n",
    "* graph (TigerGraph): Connection to the TigerGraph database.\n",
    "* batch_size (int, optional): Size of each batch. If given, `num_batches` will be recalculated based on batch size. Defaults to None.\n",
    "* num_batches (int, optional): Number of batches to split the whole dataset. Defaults to 1.\n",
    "* attributes (str, optional): Vertex attributes to get, separated by comma. Defaults to \"\".\n",
    "* local_storage_path (str, optional): Place to store data locally. Defaults to \"./tmp\".\n",
    "* cloud_storage_path (str, optional): S3 path used for cloud caching. Defaults to None.\n",
    "* buffer_size (int, optional): Number of data batches to prefetch and store in memory. Defaults to 4.\n",
    "* output_format (str, optional): Format of the output data of the loader. Only pandas dataframe is supported. Defaults to \"dataframe\".\n",
    "* aws_access_key_id (str, optional): AWS access key. Defaults to None.\n",
    "* aws_secret_access_key (str, optional): AWS access key secret. Defaults to None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87676b8-ca4f-403d-87a6-9763be1eb12e",
   "metadata": {},
   "source": [
    "#### Load all vertices at once directly to local. Default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97ade5-c5f3-41e2-b089-b55b578af5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vertex_loader = VertexLoader(tgraph, attributes=\"x,y\")\n",
    "# Note: vertex primary ID will be extracted automatically. \n",
    "# No need to specify it as an attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdb27e5-6816-4b56-b570-1af1d5179978",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Use case 1: as an iterator\n",
    "data = []\n",
    "for batch in vertex_loader:\n",
    "    data.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f7c0a0-2770-4ceb-82b1-3ab8e511f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a623004-6eb0-4af4-908e-03d89ebbaf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Use case 2: `data` property\n",
    "data = vertex_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61917bd1-a103-487b-8beb-5e87341c7cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8148f-7b40-4b5b-ab48-22cbacae090e",
   "metadata": {},
   "source": [
    "#### Stream batches of vertices directly to local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7bada1-6c98-42ec-a5c5-e72a593615f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vertex_loader = VertexLoader(tgraph, \n",
    "                             batch_size=100,\n",
    "                             attributes=\"x,y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a0531-649f-4314-b309-7bbe102dd044",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Use case 1: as an iterator\n",
    "data = []\n",
    "for batch in vertex_loader:\n",
    "    data.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bdd5fa-d6b5-47a4-a7a6-1f44c59477c8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of batches: \", len(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9727a8-e860-4fe6-9a33-54c942309815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case 2: `data` property\n",
    "# Since there are multiple batches of data. \n",
    "# The `data` property will return the loader itsel\n",
    "data = vertex_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b264a-5649-4d6d-a320-292f5f8890cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Number of batches: \", sum(1 for batch in data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f9e835-5715-4d9e-b19b-ee1f596b8aba",
   "metadata": {},
   "source": [
    "### Graph Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23581259-4981-4439-82ff-3ec71f59cb16",
   "metadata": {},
   "source": [
    "#### Load the whole graph directly to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4748c84-f9cf-48b9-a70e-2b968dfb2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgml.dataloaders import GraphLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca1a18-b862-4303-84ba-c4cad0db1581",
   "metadata": {},
   "source": [
    "For the first time you initialize the loader on a graph in TigerGraph, the initialization might take half a minute as it installs the corresponding query to the database and optimizes it. However, the query installation only needs to be done once, so it will take no time when you initialize the loader on the same TG graph again.  \n",
    "\n",
    "There are two ways to use the data loader. \n",
    "* First, it can be used as an iterator, which means you can loop through it to get every batch of data. Since this loader loads the whole graph at once, there will be only one batch of data (of the whole graph) in the iterator. \n",
    "* Second, you can access the `data` property of the class directly. Since there is only one batch of data (the whole graph), it will give you the batch directly instead of an iterator.\n",
    "\n",
    "Args to the class:\n",
    "* graph (TigerGraph): Connection to the TigerGraph database.\n",
    "* v_in_feats (str, optional): Attributes to be used as input features and their types. Attributes should be seperated by ',' and an attribute and its type should be separated by ':'. The type of an attrbiute can be omitted together with the separator ':', and the attribute will be default to type \"float32\". and Defaults to \"\".\n",
    "* v_out_labels (str, optional): Attributes to be used as labels for prediction. It follows the same format as 'v_in_feats'. Defaults to \"\".\n",
    "* v_extra_feats (str, optional): Other attributes to get such as indicators of train/test data. It follows the same format as 'v_in_feats'. Defaults to \"\".\n",
    "* local_storage_path (str, optional): Place to store data locally. Defaults to \"./tmp\".\n",
    "* cloud_storage_path (str, optional): S3 path used for cloud caching. Defaults to None.\n",
    "* buffer_size (int, optional): Number of data batches to prefetch and store in memory. Defaults to 4.\n",
    "* output_format (str, optional): Format of the output data of the loader. Only \"PyG\" is supported. Defaults to \"PyG\".\n",
    "* reindex (bool, optional): Whether to reindex the vertices. Defaults to False.\n",
    "* aws_access_key_id (str, optional): AWS access key. Defaults to None.\n",
    "* aws_secret_access_key (str, optional): AWS access key secret. Defaults to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e7d18-b57f-4cb2-b29f-fff2349ca7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "graph_loader = GraphLoader(\n",
    "                 graph = tgraph,\n",
    "                 v_in_feats = \"x:float32\",\n",
    "                 v_out_labels = \"y:int\",\n",
    "                 v_extra_feats = \"train_mask:bool,val_mask:bool,test_mask:bool\",\n",
    "                 output_format = \"PyG\",\n",
    "                 reindex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee142e99-7b15-416f-9e93-e2c72204e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Use case 1: as an iterator.\n",
    "data = []\n",
    "for batch in graph_loader:\n",
    "    data.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a0fe2-825e-44f0-8123-e0c63010d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9615d76-8c04-483c-aa1a-87782478520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Use case 2: `.data` property\n",
    "data = graph_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5049afd0-403d-4abc-98cd-6dc0ec826586",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fc6fb4-9e7b-4d7a-8c97-aa5d43b18468",
   "metadata": {},
   "source": [
    "#### Stream subgraphs with neighbor sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84654f6a-bb27-4099-a92e-be7998e75bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgml.dataloaders import NeighborLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e58134-6357-449d-afcb-15b1f63f4948",
   "metadata": {},
   "source": [
    "A data loader that performs neighbor sampling as introduced in the [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216) paper. \n",
    "\n",
    "Specifically, it first chooses `batch_size` number of vertices as seeds, then picks `num_neighbors` number of neighbors of each seed at random, then `num_neighbors` neighbors of each neighbor, and repeat for `num_hops`. This generates one subgraph. As you loop through this data loader, all vertices will be chosen as seeds and you will get all subgraphs expanded from those seeds.\n",
    "\n",
    "If you want to limit seeds to certain vertices, the boolean attribute provided to `filter_by` will be used to indicate which vertices can be included as seeds.\n",
    "\n",
    "For the first time you initialize the loader on a graph in TigerGraph, the initialization might take half a minute as it installs the corresponding query to the database and optimizes it. However, the query installation only needs to be done once, so it will take no time when you initialize the loader on the same TG graph again.  \n",
    "\n",
    "Args to this class:\n",
    "* graph (TigerGraph): Connection to the TigerGraph database.\n",
    "* tmp_id (str, optional): Attribute name that holds the temporary ID of \n",
    "                vertices. Defaults to \"tmp_id\".\n",
    "* v_in_feats (str, optional): Attributes to be used as input features and their types. Attributes should be seperated by ',' and an attribute and its type should be separated by ':'. The type of an attrbiute can be omitted together with the separator ':', and the attribute will be default to type \"float32\". and Defaults to \"\".\n",
    "* v_out_labels (str, optional): Attributes to be used as labels for prediction. It follows the same format as 'v_in_feats'. Defaults to \"\".\n",
    "* v_extra_feats (str, optional): Other attributes to get such as indicators of train/test data. It follows the same format as 'v_in_feats'. Defaults to \"\".\n",
    "* local_storage_path (str, optional): Place to store data locally. \n",
    "                Defaults to \"./tmp\".\n",
    "* cloud_storage_path (str, optional): S3 or GCP path used for cloud caching. \n",
    "                Defaults to None.\n",
    "* buffer_size (int, optional): Number of data batches to prefetch and store \n",
    "                in memory. Defaults to 4.\n",
    "* output_format (str, optional): Format of the output data of the loader. Only\n",
    "                \"PyG\" is supported. Defaults to \"PyG\".\n",
    "* batch_size (int, optional): Number of vertices as seeds in each batch. \n",
    "                Defaults to None.\n",
    "* num_batches (int, optional): Number of batches to split the vertices. \n",
    "                Defaults to 1.\n",
    "* num_neighbors (int, optional): Number of neighbors to sample for each vertex. \n",
    "                Defaults to 10.\n",
    "* num_hops (int, optional): Number of hops to traverse when sampling neighbors. \n",
    "                Defaults to 2.\n",
    "* cache_id (str, optional): A tag attached to data generated. \n",
    "                Defaults to None.\n",
    "* shuffle (bool, optional): Whether to shuffle the vertices after every epoch. \n",
    "                Defaults to False.\n",
    "* filter_by (str, optional): A boolean attribute used to indicate which vertices \n",
    "                can be included as seeds. Defaults to None.\n",
    "* aws_access_key_id (str, optional): AWS access key. Defaults to None.\n",
    "* aws_secret_access_key (str, optional): AWS access key secret. Defaults to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269bf653-ea3a-4646-aa0d-ef539838a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "graph_loader = NeighborLoader(\n",
    "                 graph = tgraph,\n",
    "                 tmp_id = \"tmp_id\",\n",
    "                 v_in_feats = \"x:float32\",\n",
    "                 v_out_labels = \"y:int\",\n",
    "                 v_extra_feats = \"train_mask:bool,val_mask:bool,test_mask:bool\",\n",
    "                 output_format = \"PyG\",\n",
    "                 batch_size = 64,\n",
    "                 num_neighbors = 10,\n",
    "                 num_hops =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc82350c-9e80-4ff1-8c1b-67ae60a75a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = []\n",
    "for batch in graph_loader:\n",
    "    data.append(batch)\n",
    "print(\"Number of batches: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7798d8b2-8c7e-4dca-bb7b-2bd32854311e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520ef23-0acc-4e5e-9b31-1ed019b42ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "graph_loader = NeighborLoader(\n",
    "                 graph = tgraph,\n",
    "                 tmp_id = \"tmp_id\",\n",
    "                 v_in_feats = \"x:float32\",\n",
    "                 v_out_labels = \"y:int\",\n",
    "                 v_extra_feats = \"train_mask:bool,val_mask:bool,test_mask:bool\",\n",
    "                 output_format = \"PyG\",\n",
    "                 batch_size = 16,\n",
    "                 num_neighbors = 10,\n",
    "                 num_hops =2,\n",
    "                 filter_by = \"train_mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528f6ca7-e769-4c17-a129-89153bbefc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = []\n",
    "for batch in graph_loader:\n",
    "    data.append(batch)\n",
    "print(\"Number of batches: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e95143-fd11-4af1-8d9a-6c80a2f2e646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22728e2e-f3e1-4e97-b7a6-754813279f38",
   "metadata": {},
   "source": [
    "### Smart Cloud Caching\n",
    "\n",
    "When you provide `cloud_storage_path` when creating a loader (including all vertex, edge, graph loaders), data will be moved to a cloud storage first and then downloaded to local, so it will be slower compared to streaming directly from the server. However, when there are multiple consumers of the same data such as when trying out different models in parallel or tuning hyperparameters, the cloud caching would reduce workload of the server, and consequently it might be faster than hitting the server from multiple consumers at the same time.\n",
    "\n",
    "To share the cloud cache between different consumers, provide the same `cache_id` when creating the loaders. Below we create two loaders in this same python session to demo the use of cloud caching; in practice, you would run parallel python sessions with each having its own loader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1627b-a960-4c5c-9dce-9eb8a6028403",
   "metadata": {},
   "outputs": [],
   "source": [
    "VertexLoader(cloud_storage_path=\"s3://ohai\", aw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b43e77-48d7-40b8-ad25-ec1dc2a224b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vertex_loader = VertexLoader(tgraph, \n",
    "                             batch_size=100,\n",
    "                             attributes=\"x,y\",\n",
    "                             cache_id=\"test_smart_cache\",\n",
    "                             cloud_storage_path=\"s3://graph-export-dev/cora_vertices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2923e7e8-9551-4f80-bbbe-6938106dd609",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = []\n",
    "for batch in vertex_loader:\n",
    "    data.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d3e14-092b-4e06-88ca-644a22ce703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cfe835-1971-417d-b057-b81bb89888c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vertex_loader2 = VertexLoader(tgraph, \n",
    "                             batch_size=100,\n",
    "                             attributes=\"x,y\",\n",
    "                             cache_id=\"test_smart_cache\",\n",
    "                             cloud_storage_path=\"s3://graph-export-dev/cora_vertices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352cf26-10c5-4050-a4aa-ea6286e6415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data2 = []\n",
    "for batch in vertex_loader2:\n",
    "    data2.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc0620-9f08-49b4-89b8-51ae407b5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d1,d2 in zip(data,data2):\n",
    "    assert all(d1==d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef117c4-b092-4a4c-a103-9147043e61fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
