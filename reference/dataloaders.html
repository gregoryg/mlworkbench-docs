<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>tgml.dataloaders API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tgml.dataloaders</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import io
import logging
import math
import os
from queue import Empty, Queue
from threading import Event, Thread
from typing import NoReturn
from urllib.parse import urlparse
from zipfile import ZipFile

import numpy as np
import pandas as pd
import torch
from dotenv import load_dotenv
from pandas import DataFrame
from torch_geometric.data import Data as pygData

from .data import TigerGraph
from .extras.utilities import (download_from_gcs, download_from_s3,
                               random_string)

__all__ = [&#34;VertexLoader&#34;, &#34;EdgeLoader&#34;, &#34;GraphLoader&#34;, &#34;NeighborLoader&#34;]
__pdoc__ = {&#34;VertexLoader.start_reader&#34;: False,
            &#34;GraphLoader.start_reader&#34;: False,
            &#34;GraphLoader.start_requester&#34;: False,
            &#34;NeighborLoader.start_reader&#34;: False,
            &#34;NeighborLoader.start_requester&#34;: False}


class BaseLoader:
    def __init__(self,
                 graph: TigerGraph,
                 local_storage_path: str,
                 cloud_storage_path: str,
                 buffer_size: int,
                 output_format: str,
                 num_batches: int,
                 cache_id: str = None,
                 aws_access_key_id: str = None,
                 aws_secret_access_key: str = None):
        &#34;&#34;&#34;Base Class for data loaders.

        The job of a data loader is to pull data from the TigerGraph database. 
        It can either stream data directly from the server or cache data on the cloud. 
        For the latter, data will be moved to a cloud storage first and then downloaded 
        to local, so it will be slower compared to streaming directly from the server. 
        However, when there are multiple consumers of the same data such as when trying 
        out different models in parallel or tuning hyperparameters, the cloud caching 
        would reduce workload of the server, and consequently it might be faster than 
        hitting the server from multiple consumers at the same time. 

        If using cloud caching, cloud storage access keys need to be provided. For AWS
        s3, `aws_access_key_id` and `aws_secret_access_key` are required.  

        For the first time you initialize the loader on a graph in TigerGraph, 
        the initialization might take half a minute as it installs the corresponding 
        query to the database and optimizes it. However, the query installation only 
        needs to be done once, so it will take no time when you initialize the loader 
        on the same TG graph again.

        Note: For the data loader to work, the *Graph Data Processing Service* has to be 
        running on the TigerGraph server.

        Args:
            graph (TigerGraph): Connection to the TigerGraph database.
            local_storage_path (str): Place to store data locally.
            cloud_storage_path (str): S3 used for cloud caching.
            buffer_size (int): Number of data batches to prefetch and store in memory.
            output_format (str): Format of the output data of the loader.
            num_batches (int): Number of batches to split the whole dataset.
            aws_access_key_id (str, optional): AWS access key. Defaults to None.
            aws_secret_access_key (str, optional): AWS access key secret. Defaults to None.
        &#34;&#34;&#34;
        self._graph = graph
        if (not cloud_storage_path) or (not cache_id):
            self.cache_id = random_string(6)
        else:
            self.cache_id = cache_id
        self._iterations = 0
        self._payload = {&#34;graph&#34;: graph.graph_name,
                         &#34;cloud_storage_path&#34;: cloud_storage_path,
                         &#34;num_batches&#34;: num_batches,
                         &#34;cache_id&#34;: self.cache_id,
                         &#34;iterations&#34;: self._iterations}
        self.output_format = output_format
        self.num_batches = num_batches
        self.fulfilled_batches = 0
        # Resolve paths
        self._local_storage_path = local_storage_path
        self._cloud_storage_path = cloud_storage_path
        self._buffer_size = buffer_size
        os.makedirs(local_storage_path, exist_ok=True)
        self._base_endpoint = &#34;{}:8000&#34;.format(graph.host)
        # Thread to call database
        self._requester = None
        # Threads to download and load data
        self._downloader = None
        self._reader = None
        # Queues to store tasks and data
        self._request_task_q = None
        self._download_task_q = None
        self._read_task_q = None
        self._data_q = None
        # Exit signal to terminate threads
        self._exit_event = None
        # In-memory data cache. Only used if num_batches=1
        self._data = None
        # Resolve cloud storage keys if cloud storage is used
        self._cloud_keys = None
        if cloud_storage_path:
            if urlparse(cloud_storage_path).scheme == &#34;s3&#34;:
                load_dotenv()
                if not aws_access_key_id:
                    aws_access_key_id = os.getenv(&#39;AWS_ACCESS_KEY_ID&#39;)
                if not aws_secret_access_key:
                    aws_secret_access_key = os.getenv(&#34;AWS_SECRET_ACCESS_KEY&#34;)
                if not (aws_access_key_id and aws_secret_access_key):
                    raise Exception(&#34;AWS access keys not found&#34;)
                self._cloud_keys = aws_access_key_id+&#39; &#39;+aws_secret_access_key

    @staticmethod
    def _request(exit_event: Event, in_q: Queue, out_q: Queue,
                 endpoint: str, params: dict, tgraph: TigerGraph,
                 headers: dict = None, tuple_resp: bool = False) -&gt; NoReturn:
        _params = {}
        _params.update(params)
        while not exit_event.is_set():
            task = in_q.get()
            if task is None:
                in_q.task_done()
                out_q.put(None)
                break
            batch_id, num_batches = task
            _params[&#34;batch_id&#34;] = batch_id
            _params[&#34;num_batches&#34;] = num_batches
            try:
                resp = tgraph._rest_session.get(endpoint, params=_params,
                                                headers=headers)
            except:
                logging.warning(
                    &#34;Encountered Connection Error. Retry batch {} later.&#34;.format(batch_id))
                in_q.task_done()
                in_q.put((batch_id, num_batches))
                continue

            if _params[&#34;cloud_storage_path&#34;]:
                # Data are cached in cloud. Put them into download queue.
                resp_json = resp.json()
                if tuple_resp:
                    cloud_file_path = (
                        resp_json[&#34;vertex_file&#34;], resp_json[&#34;edge_file&#34;])
                else:
                    cloud_file_path = resp_json[&#34;file_path&#34;]
                out_q.put(cloud_file_path)
            else:
                # Data are returned in the response.
                if tuple_resp:
                    zip_io = ZipFile(io.BytesIO(resp.content))
                    out_q.put(zip_io)
                else:
                    out_q.put(resp.content)
            in_q.task_done()

    @staticmethod
    def _download_from_cloud(exit_event: Event, in_q: Queue, out_q: Queue,
                             local_dir: str, cloud_keys: str) -&gt; NoReturn:
        def parse_and_download(cloud_url, local_dir, cloud_keys):
            parsed_cloud_url = urlparse(cloud_url)
            if parsed_cloud_url.scheme == &#34;gs&#34;:
                local_file = download_from_gcs(cloud_url, local_dir)
            elif parsed_cloud_url.scheme == &#34;s3&#34;:
                try:
                    aws_access_key_id, aws_secret_access_key = cloud_keys.split(
                        &#39; &#39;)
                except:
                    raise Exception(&#34;AWS access keys not found&#34;)
                local_file = download_from_s3(
                    cloud_url, local_dir, aws_access_key_id, aws_secret_access_key)
            else:
                raise NotImplementedError
            return local_file

        while not exit_event.is_set():
            cloud_url = in_q.get()
            if cloud_url is None:
                in_q.task_done()
                out_q.put(None)
                break
            if isinstance(cloud_url, tuple) and len(cloud_url) == 2:
                # There is a pair of files (edges, vertices) to download
                v_url, e_url = cloud_url
                v_file = parse_and_download(v_url, local_dir, cloud_keys)
                e_file = parse_and_download(e_url, local_dir, cloud_keys)
                out_q.put((v_file, e_file))
            else:
                # There is only one file to download
                local_file = parse_and_download(
                    cloud_url, local_dir, cloud_keys)
                out_q.put(local_file)
            in_q.task_done()

    @staticmethod
    def _read_file(exit_event: Event,
                   in_q: Queue,
                   out_q: Queue,
                   out_format: str = &#34;dataframe&#34;,
                   v_in_feats: str = &#34;&#34;,
                   v_out_labels: str = &#34;&#34;,
                   v_extra_feats: str = &#34;&#34;,
                   reindex: bool = False) -&gt; NoReturn:

        def _parse_csv(data,
                       sep: str = &#39;,&#39;,
                       headers: list = None,
                       out_format: str = &#34;dataframe&#34;):
            if out_format.lower() == &#34;dataframe&#34;:
                if headers:
                    df = pd.read_csv(data, sep=sep, header=None, names=headers)
                else:
                    df = pd.read_csv(data, sep=sep, header=None)
            else:
                raise NotImplementedError
            return df

        def attr_to_tensor(attributes: str, df: pd.DataFrame) -&gt; torch.Tensor:
            x = []
            for attr in attributes.split(&#39;,&#39;):
                if &#39;:&#39; in attr:
                    col, dtype = attr.split(&#39;:&#39;)
                    dtype = dtype.lower()
                else:
                    col, dtype = attr, &#34;float32&#34;
                if df[col].dtype == &#34;object&#34;:
                    x.append(df[col].str.split(
                        expand=True).to_numpy().astype(dtype))
                else:
                    x.append(
                        df[[col]].to_numpy().astype(dtype))
            return torch.tensor(np.hstack(x).squeeze())

        attributes = [j.split(&#39;:&#39;)[0] for i in filter(
            None, (v_in_feats, v_out_labels, v_extra_feats)) for j in i.split(&#39;,&#39;)]
        headers = [&#34;primary_id&#34;] + attributes if attributes else None

        while not exit_event.is_set():
            raw = in_q.get()
            if raw is None:
                in_q.task_done()
                out_q.put(None)
                break
            if isinstance(raw, bytes):
                # Data is an in-memory file
                data = _parse_csv(io.BytesIO(
                    raw), headers=headers, out_format=out_format)
            elif isinstance(raw, str):
                # Data is in a file on disk
                data = _parse_csv(raw, headers=headers, out_format=out_format)
            elif isinstance(raw, ZipFile):
                # Data is in a pair of files (edges, vertices) in a zipfile
                with raw.open(&#34;vertices.csv&#34;) as infile:
                    vertices = _parse_csv(
                        infile, headers=headers, out_format=&#34;dataframe&#34;)
                with raw.open(&#34;edges.csv&#34;) as infile:
                    edges = _parse_csv(
                        infile, headers=[&#34;source&#34;, &#34;target&#34;], out_format=&#34;dataframe&#34;)
                raw.close()
                data = (vertices, edges)
            elif isinstance(raw, tuple):
                # Data is in a pair of files (e_file, v_file) on disk
                v_file, e_file = raw
                edges = _parse_csv(
                    e_file, headers=[&#34;source&#34;, &#34;target&#34;], out_format=&#34;dataframe&#34;)
                vertices = _parse_csv(
                    v_file, headers=headers, out_format=&#34;dataframe&#34;)
                data = (vertices, edges)
            else:
                raise NotImplementedError

            if out_format.lower() == &#34;pyg&#34;:
                data = pygData()
                # Reformat as a PyG graph.
                # Need to have a pair of tables for edges and vertices.
                # Deal with edgelist first
                if reindex:
                    vertices[&#34;tmp_id&#34;] = range(len(vertices))
                    id_map: DataFrame = vertices[[&#34;primary_id&#34;, &#34;tmp_id&#34;]]
                    edges: DataFrame = edges.merge(
                        id_map, left_on=&#34;source&#34;, right_on=&#34;primary_id&#34;)
                    edges.drop(columns=[&#34;source&#34;, &#34;primary_id&#34;], inplace=True)
                    edges: DataFrame = edges.merge(
                        id_map, left_on=&#34;target&#34;, right_on=&#34;primary_id&#34;)
                    edges.drop(columns=[&#34;target&#34;, &#34;primary_id&#34;], inplace=True)
                    edges: DataFrame = edges[[&#34;tmp_id_x&#34;, &#34;tmp_id_y&#34;]]
                else:
                    vertices.sort_values(&#34;primary_id&#34;, inplace=True)
                data[&#34;edge_index&#34;] = torch.tensor(
                    edges.to_numpy().T, dtype=torch.long)
                del edges
                # Deal with vertex attributes next
                if v_in_feats:
                    data[&#39;x&#39;] = attr_to_tensor(v_in_feats, vertices)
                if v_out_labels:
                    data[&#39;y&#39;] = attr_to_tensor(v_out_labels, vertices)
                if v_extra_feats:
                    for attr in v_extra_feats.split(&#39;,&#39;):
                        if &#39;:&#39; in attr:
                            col, dtype = attr.split(&#39;:&#39;)
                            dtype = dtype.lower()
                        else:
                            col, dtype = attr, &#34;float32&#34;
                        if vertices[col].dtype == &#34;object&#34;:
                            data[col] = torch.tensor(vertices[col].str.split(
                                expand=True).to_numpy().astype(dtype))
                        else:
                            data[col] = torch.tensor(
                                vertices[col].to_numpy().astype(dtype))
                del vertices
            elif out_format.lower() == &#34;dataframe&#34;:
                pass
            else:
                raise NotImplementedError
            out_q.put(data)
            in_q.task_done()

    def start_requester(self, out_q: Queue) -&gt; None:
        args = (self._exit_event,
                self._request_task_q,
                out_q,
                self._base_endpoint+&#34;/run&#34;,
                self._payload,
                self._graph,
                {&#34;cloud-keys&#34;: self._cloud_keys})
        self._requester = Thread(target=self._request, args=args)
        self._requester.start()

    def start_downloader(self) -&gt; None:
        self._downloader = Thread(target=self._download_from_cloud,
                                  args=(self._exit_event,
                                        self._download_task_q,
                                        self._read_task_q,
                                        self._local_storage_path,
                                        self._cloud_keys))
        self._downloader.start()

    def start_reader(self) -&gt; None:
        self._reader = Thread(target=self._read_file,
                              args=(self._exit_event,
                                    self._read_task_q,
                                    self._data_q))

        self._reader.start()

    def start(self) -&gt; None:
        self._request_task_q = Queue()
        self._read_task_q = Queue()
        self._data_q = Queue(self._buffer_size)
        self._exit_event = Event()
        if self._cloud_storage_path:
            self._download_task_q = Queue()
            request_out_q = self._download_task_q
            self.start_downloader()
        else:
            request_out_q = self._read_task_q

        self.start_requester(request_out_q)
        self.start_reader()

        # Populate request queue with the batches to get.
        for i in range(self.num_batches):
            self._request_task_q.put((i, self.num_batches))

    def __iter__(self):
        if self.num_batches == 1:
            return iter([self.data])
        self.reset()
        self.start()
        self._iterations += 1
        self._payload[&#34;iterations&#34;] = self._iterations
        return self

    def __next__(self):
        if not self._data_q:
            raise StopIteration
        data = self._data_q.get()
        if data is None:
            raise StopIteration
        self.fulfilled_batches += 1
        if self.fulfilled_batches == self.num_batches:
            # Signal for stop
            self._request_task_q.put(None)
            self.fulfilled_batches = 0
        return data

    @property
    def data(self):
        if self.num_batches == 1:
            if self._data is None:
                self.reset()
                self.start()
                self._data = self._data_q.get()
                self._request_task_q.put(None)
            return self._data
        else:
            return self

    def reset(self) -&gt; None:
        if self._exit_event:
            self._exit_event.set()
        if self._request_task_q:
            self._request_task_q.put(None)
        if self._download_task_q:
            self._download_task_q.put(None)
        if self._read_task_q:
            self._read_task_q.put(None)
        if self._data_q:
            while True:
                try:
                    self._data_q.get(block=False)
                except Empty:
                    break
        logging.debug(&#34;Shutting down previous iterator threads&#34;)
        if self._requester:
            self._requester.join()
        if self._downloader:
            self._downloader.join()
        if self._reader:
            self._reader.join()
        del self._request_task_q, self._download_task_q, self._read_task_q, self._data_q
        self._exit_event = None
        self._requester, self._downloader, self._reader = None, None, None
        self._request_task_q, self._download_task_q, self._read_task_q, self._data_q = None, None, None, None
        logging.debug(&#34;Successfully terminated previous iterator threads&#34;)


class EdgeLoader(BaseLoader):
    def __init__(self,
                 graph: TigerGraph,
                 batch_size: int = None,
                 num_batches: int = 1,
                 local_storage_path: str = &#34;./tmp&#34;,
                 cloud_storage_path: str = None,
                 buffer_size: int = 4,
                 output_format: str = &#34;dataframe&#34;,
                 cache_id: str = None,
                 aws_access_key_id: str = None,
                 aws_secret_access_key: str = None) -&gt; None:
        &#34;&#34;&#34;Data loader that pulls either the whole edgelist or batches of edges from database. 
        Edge attributes are not supported.

        **Note**: For the first time you initialize the loader on a graph in TigerGraph, 
        the initialization might take half a minute as it installs the corresponding 
        query to the database and optimizes it. However, the query installation only 
        needs to be done once, so it will take no time when you initialize the loader 
        on the same TG graph again. For the data loader to work, the *Graph Data Processing Service* 
        has to be running on the TigerGraph server.

        There are two ways to use the data loader. See [here](https://github.com/tg-bill/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb) for examples.

        * First, it can be used as an iterator, which means you can loop through 
          it to get every batch of data. If you load all edges at once (`num_batches=1`), 
          there will be only one batch (of all the edges) in the iterator.
        * Second, you can access the `data` property of the class directly. If there is 
          only one batch of data to load, it will give you the batch directly instead 
          of an iterator, which might make more sense in that case. If there are 
          multiple batches of data to load, it will return the loader again.

        It can either stream data directly from the server or cache data on the cloud. 
        Set `cloud_storage_path` to turn on cloud cache. This way data will be moved to 
        a cloud storage first and then downloaded 
        to local, so it will be slower compared to streaming directly from the server. 
        However, when there are multiple consumers of the same data such as when trying 
        out different models in parallel or tuning hyperparameters, the cloud caching 
        would reduce workload of the server, and consequently it might be faster overall. 
        If using cloud caching, cloud storage access keys need to be provided. For AWS s3, 
        `aws_access_key_id` and `aws_secret_access_key` are required. However, the class can 
        read from environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`, 
        and again it is recommended to store those credentials in the `.env` file instead of hardcoding them. 

        Args:
            graph (TigerGraph): Connection to the TigerGraph database.
            batch_size (int, optional): Size of each batch. If given, `num_batches` 
                will be recalculated based on batch size. Defaults to None.
            num_batches (int, optional): Number of batches to split the whole dataset. 
                Defaults to 1.
            local_storage_path (str, optional): Place to store data locally. 
                Defaults to &#34;./tmp&#34;.
            cloud_storage_path (str, optional): S3 path used for cloud caching. If not None, cloud caching will be used.
                Defaults to None.
            buffer_size (int, optional): Number of data batches to prefetch and store 
                in memory. Defaults to 4.
            output_format (str, optional): Format of the output data of the loader. 
                Only pandas dataframe is supported. Defaults to &#34;dataframe&#34;.
            cache_id (str, optional): An identifier associated to data from this loader. If none, a random string will be used automatically. Defaults to None.
            aws_access_key_id (str, optional): AWS access key for cloud storage. Defaults to None.
            aws_secret_access_key (str, optional): AWS access key secret for cloud storage. Defaults to None.
        &#34;&#34;&#34;
        super().__init__(graph, local_storage_path, cloud_storage_path,
                         buffer_size, output_format, num_batches, cache_id,
                         aws_access_key_id, aws_secret_access_key)
        # If batch_size is given, calculate the number of batches
        if batch_size:
            self.batch_size = batch_size
            self.num_batches = math.ceil(
                self._graph.number_of_edges()/batch_size)
        else:
            self.num_batches = num_batches
            self.batch_size = math.ceil(
                self._graph.number_of_edges()/num_batches)
        # Initialize the exporter
        self._base_endpoint += &#34;/export/edges&#34;
        self._payload[&#34;num_batches&#34;] = self.num_batches
        self._graph._mixed_session.get(
            self._base_endpoint+&#34;/init&#34;, params=self._payload)


class VertexLoader(BaseLoader):
    def __init__(self,
                 graph: TigerGraph,
                 batch_size: int = None,
                 num_batches: int = 1,
                 attributes: str = &#34;&#34;,
                 local_storage_path: str = &#34;./tmp&#34;,
                 cloud_storage_path: str = None,
                 buffer_size: int = 4,
                 output_format: str = &#34;dataframe&#34;,
                 cache_id: str = None,
                 aws_access_key_id: str = None,
                 aws_secret_access_key: str = None) -&gt; None:
        &#34;&#34;&#34;Data loader that pulls either all the vertices or batches of vertices from database. 

        **Note**: For the first time you initialize the loader on a graph in TigerGraph, 
        the initialization might take half a minute as it installs the corresponding 
        query to the database and optimizes it. However, the query installation only 
        needs to be done once, so it will take no time when you initialize the loader 
        on the same TG graph again. For the data loader to work, the *Graph Data Processing Service* 
        has to be running on the TigerGraph server.

        There are two ways to use the data loader.

        * First, it can be used as an iterator, which means you can loop through 
          it to get every batch of data. If you load all vertices at once (`num_batches=1`), 
          there will be only one batch (of all the vertices) in the iterator.
        * Second, you can access the `data` property of the class directly. If there is 
          only one batch of data to load, it will give you the batch directly instead 
          of an iterator, which might make more sense in that case. If there are 
          multiple batches of data to load, it will return the loader again.

        It can either stream data directly from the server or cache data on the cloud. 
        Set `cloud_storage_path` to turn on cloud cache. This way data will be moved to 
        a cloud storage first and then downloaded 
        to local, so it will be slower compared to streaming directly from the server. 
        However, when there are multiple consumers of the same data such as when trying 
        out different models in parallel or tuning hyperparameters, the cloud caching 
        would reduce workload of the server, and consequently it might be faster overall. 
        If using cloud caching, cloud storage access keys need to be provided. For AWS s3, 
        `aws_access_key_id` and `aws_secret_access_key` are required. However, the class 
        can read from environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`, 
        and hence it is recommended to store those credentials in the `.env` file instead of hardcoding them.  

        Args:
            graph (TigerGraph): Connection to the TigerGraph database.
            batch_size (int, optional): Size of each batch. If given, `num_batches` 
                will be recalculated based on batch size. Defaults to None.
            num_batches (int, optional): Number of batches to split the whole dataset. 
                Defaults to 1.
            attributes (str, optional): Vertex attributes to get, separated by comma. 
                Defaults to &#34;&#34;.
            local_storage_path (str, optional): Place to store data locally. 
                Defaults to &#34;./tmp&#34;.
            cloud_storage_path (str, optional): S3 path used for cloud caching. If not None, cloud caching will be used.
                Defaults to None.
            buffer_size (int, optional): Number of data batches to prefetch and store 
                in memory. Defaults to 4.
            output_format (str, optional): Format of the output data of the loader. 
                Only pandas dataframe is supported. Defaults to &#34;dataframe&#34;.
            cache_id (str, optional): An identifier associated to data from this loader. If none, a random string will be used automatically. Defaults to None.
            aws_access_key_id (str, optional): AWS access key for cloud storage. Defaults to None.
            aws_secret_access_key (str, optional): AWS access key secret for cloud storage. Defaults to None.
        &#34;&#34;&#34;
        super().__init__(graph, local_storage_path, cloud_storage_path,
                         buffer_size, output_format, num_batches, cache_id,
                         aws_access_key_id, aws_secret_access_key)
        self.attributes = attributes
        # If batch_size is given, calculate the number of batches
        if batch_size:
            self.batch_size = batch_size
            self.num_batches = math.ceil(
                self._graph.number_of_vertices()/batch_size)
        else:
            self.num_batches = num_batches
            self.batch_size = math.ceil(
                self._graph.number_of_vertices()/num_batches)
        # Initialize the exporter
        self._base_endpoint += &#34;/export/vertices&#34;
        self._payload[&#34;num_batches&#34;] = self.num_batches
        self._payload[&#34;attributes&#34;] = attributes
        self._graph._mixed_session.get(
            self._base_endpoint+&#34;/init&#34;, params=self._payload)

    def start_reader(self) -&gt; None:
        self._reader = Thread(target=self._read_file,
                              args=(self._exit_event,
                                    self._read_task_q,
                                    self._data_q,
                                    self.output_format,
                                    self.attributes))
        self._reader.start()


class GraphLoader(BaseLoader):
    def __init__(self,
                 graph: TigerGraph,
                 v_in_feats: str = &#34;&#34;,
                 v_out_labels: str = &#34;&#34;,
                 v_extra_feats: str = &#34;&#34;,
                 local_storage_path: str = &#34;./tmp&#34;,
                 cloud_storage_path: str = None,
                 buffer_size: int = 4,
                 output_format: str = &#34;PyG&#34;,
                 num_batches: int = 1,
                 cache_id: str = None,
                 reindex: bool = False,
                 aws_access_key_id: str = None,
                 aws_secret_access_key: str = None) -&gt; None:
        &#34;&#34;&#34;Data loader that pulls the whole graph from database. 

        **Note**: For the first time you initialize the loader on a graph in TigerGraph, 
        the initialization might take half a minute as it installs the corresponding 
        query to the database and optimizes it. However, the query installation only 
        needs to be done once, so it will take no time when you initialize the loader 
        on the same TG graph again. For the data loader to work, the *Graph Data Processing Service* 
        has to be running on the TigerGraph server.

        There are two ways to use the data loader. See [here](https://github.com/tg-bill/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb) for examples.

        * First, it can be used as an iterator, which means you can loop through it to get every batch of data. Since this loader loads the whole graph at once, there will be only one batch of data (of the whole graph) in the iterator.
        * Second, you can access the `data` property of the class directly. Since there is only one batch of data (the whole graph), it will give you the batch directly instead of an iterator.

        It can either stream data directly from the server or cache data on the cloud. 
        Set `cloud_storage_path` to turn on cloud cache. This way data will be moved to 
        a cloud storage first and then downloaded 
        to local, so it will be slower compared to streaming directly from the server. 
        However, when there are multiple consumers of the same data such as when trying 
        out different models in parallel or tuning hyperparameters, the cloud caching 
        would reduce workload of the server, and consequently it might be faster overall. 
        If using cloud caching, cloud storage access keys need to be provided. For AWS s3, 
        `aws_access_key_id` and `aws_secret_access_key` are required. However, the class 
        can read from environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`, 
        and hence it is recommended to store those credentials in the `.env` file instead of hardcoding them. 

        Args:
            graph (TigerGraph): Connection to the TigerGraph database.
            v_in_feats (str, optional): Attributes to be used as input features and their types. Attributes should be seperated by &#39;,&#39; and an attribute and its type should be separated by &#39;:&#39;. The type of an attrbiute can be omitted together with the separator &#39;:&#39;, and the attribute will be default to type &#34;float32&#34;. Defaults to &#34;&#34;.
            v_out_labels (str, optional): Attributes to be used as labels for prediction. It follows the same format as &#39;v_in_feats&#39;. Defaults to &#34;&#34;.
            v_extra_feats (str, optional): Other attributes to get such as indicators of train/test data. It follows the same format as &#39;v_in_feats&#39;. Defaults to &#34;&#34;.
            local_storage_path (str, optional): Place to store data locally. 
                Defaults to &#34;./tmp&#34;.
            cloud_storage_path (str, optional): S3 path used for cloud caching. If not None, cloud caching will be used.
                Defaults to None.
            buffer_size (int, optional): Number of data batches to prefetch and store 
                in memory. Defaults to 4.
            output_format (str, optional): Format of the output data of the loader. Only
                &#34;PyG&#34; is supported. Defaults to &#34;PyG&#34;.
            reindex (bool, optional): Whether to reindex the vertices. Defaults to False.
            cache_id (str, optional): An identifier associated to data from this loader. If none, a random string will be used automatically. Defaults to None.
            aws_access_key_id (str, optional): AWS access key for cloud storage. Defaults to None.
            aws_secret_access_key (str, optional): AWS access key secret for cloud storage. Defaults to None.
        &#34;&#34;&#34;
        super().__init__(graph, local_storage_path, cloud_storage_path,
                         buffer_size, output_format, num_batches, cache_id,
                         aws_access_key_id, aws_secret_access_key)
        self.reindex = reindex
        # Resolve attributes
        v_attributes = [j.split(&#39;:&#39;)[0] for i in filter(
            None, (v_in_feats, v_out_labels, v_extra_feats)) for j in i.split(&#39;,&#39;)]
        self.v_in_feats = v_in_feats
        self.v_out_labels = v_out_labels
        self.v_extra_feats = v_extra_feats
        # Initialize the exporter
        self._base_endpoint += &#34;/export/graph&#34;
        self._payload[&#34;v_attributes&#34;] = &#39;,&#39;.join(v_attributes)
        resp = self._graph._mixed_session.get(
            self._base_endpoint+&#34;/init&#34;, params=self._payload)
        resp.raise_for_status()

    def start_requester(self, out_q: Queue) -&gt; None:
        args = (self._exit_event,
                self._request_task_q,
                out_q,
                self._base_endpoint+&#34;/run&#34;,
                self._payload,
                self._graph,
                {&#34;cloud-keys&#34;: self._cloud_keys},
                True)
        self._requester = Thread(target=self._request, args=args)
        self._requester.start()

    def start_reader(self) -&gt; None:
        self._reader = Thread(target=self._read_file,
                              args=(self._exit_event,
                                    self._read_task_q,
                                    self._data_q,
                                    self.output_format,
                                    self.v_in_feats,
                                    self.v_out_labels,
                                    self.v_extra_feats,
                                    self.reindex))
        self._reader.start()


class NeighborLoader(BaseLoader):
    def __init__(self,
                 graph: TigerGraph,
                 tmp_id: str = &#34;tmp_id&#34;,
                 v_in_feats: str = &#34;&#34;,
                 v_out_labels: str = &#34;&#34;,
                 v_extra_feats: str = &#34;&#34;,
                 local_storage_path: str = &#34;./tmp&#34;,
                 cloud_storage_path: str = None,
                 buffer_size: int = 4,
                 output_format: str = &#34;PyG&#34;,
                 batch_size: int = None,
                 num_batches: int = 1,
                 num_neighbors: int = 10,
                 num_hops: int = 2,
                 cache_id: str = None,
                 shuffle: bool = False,
                 filter_by: str = None,
                 aws_access_key_id: str = None,
                 aws_secret_access_key: str = None) -&gt; None:
        &#34;&#34;&#34;A data loader that performs neighbor sampling as introduced in the 
        [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216) paper. 

        Specifically, it first chooses `batch_size` number of vertices as seeds, 
        then picks `num_neighbors` number of neighbors of each seed at random, 
        then `num_neighbors` neighbors of each neighbor, and repeat for `num_hops`. 
        This generates one subgraph. As you loop through this data loader, all 
        vertices will be chosen as seeds and you will get all subgraphs expanded from those seeds.

        If you want to limit seeds to certain vertices, the boolean attribute provided to `filter_by` will be used to indicate which vertices can be included as seeds.

        **Note**: For the first time you initialize the loader on a graph in TigerGraph, 
        the initialization might take half a minute as it installs the corresponding 
        query to the database and optimizes it. However, the query installation only 
        needs to be done once, so it will take no time when you initialize the loader 
        on the same TG graph again. For the data loader to work, the *Graph Data Processing Service* 
        has to be running on the TigerGraph server.

        There are two ways to use the data loader. See [here](https://github.com/tg-bill/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb) for examples.

        * First, it can be used as an iterator, which means you can loop through 
          it to get every batch of data. If you load all edges at once (`num_batches=1`), 
          there will be only one batch (of all the edges) in the iterator.
        * Second, you can access the `data` property of the class directly. If there is 
          only one batch of data to load, it will give you the batch directly instead 
          of an iterator, which might make more sense in that case. If there are 
          multiple batches of data to load, it will return the loader again.

        It can either stream data directly from the server or cache data on the cloud. 
        Set `cloud_storage_path` to turn on cloud cache. This way data will be moved to 
        a cloud storage first and then downloaded 
        to local, so it will be slower compared to streaming directly from the server. 
        However, when there are multiple consumers of the same data such as when trying 
        out different models in parallel or tuning hyperparameters, the cloud caching 
        would reduce workload of the server, and consequently it might be faster overall. 
        If using cloud caching, cloud storage access keys need to be provided. For AWS s3, 
        `aws_access_key_id` and `aws_secret_access_key` are required. However, the class 
        can read from environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`, 
        and hence it is recommended to store those credentials in the `.env` file instead of hardcoding them. 

        Args:
            graph (TigerGraph): Connection to the TigerGraph database.
            tmp_id (str, optional): Attribute name that holds the temporary ID of 
                vertices. Defaults to &#34;tmp_id&#34;.
            v_in_feats (str, optional): Attributes to be used as input features and their types. Attributes should be seperated by &#39;,&#39; and an attribute and its type should be separated by &#39;:&#39;. The type of an attrbiute can be omitted together with the separator &#39;:&#39;, and the attribute will be default to type &#34;float32&#34;. and Defaults to &#34;&#34;.
            v_out_labels (str, optional): Attributes to be used as labels for prediction. It follows the same format as &#39;v_in_feats&#39;. Defaults to &#34;&#34;.
            v_extra_feats (str, optional): Other attributes to get such as indicators of train/test data. It follows the same format as &#39;v_in_feats&#39;. Defaults to &#34;&#34;.
            local_storage_path (str, optional): Place to store data locally. 
                Defaults to &#34;./tmp&#34;.
            cloud_storage_path (str, optional): S3 path used for cloud caching. If not None, cloud caching will be used.
                Defaults to None.
            buffer_size (int, optional): Number of data batches to prefetch and store 
                in memory. Defaults to 4.
            output_format (str, optional): Format of the output data of the loader. Only
                &#34;PyG&#34; is supported. Defaults to &#34;PyG&#34;.
            batch_size (int, optional): Number of vertices as seeds in each batch. 
                Defaults to None.
            num_batches (int, optional): Number of batches to split the vertices. 
                Defaults to 1.
            num_neighbors (int, optional): Number of neighbors to sample for each vertex. 
                Defaults to 10.
            num_hops (int, optional): Number of hops to traverse when sampling neighbors. 
                Defaults to 2.
            shuffle (bool, optional): Whether to shuffle the vertices after every epoch. 
                Defaults to False.
            filter_by (str, optional): A boolean attribute used to indicate which vertices 
                can be included as seeds. Defaults to None.
            cache_id (str, optional): An identifier associated to data from this loader. If none, a random string will be used automatically. Defaults to None.
            aws_access_key_id (str, optional): AWS access key for cloud storage. Defaults to None.
            aws_secret_access_key (str, optional): AWS access key secret for cloud storage. Defaults to None.
        &#34;&#34;&#34;
        super().__init__(graph, local_storage_path, cloud_storage_path,
                         buffer_size, output_format, num_batches, cache_id,
                         aws_access_key_id, aws_secret_access_key)
        # Resolve attributes
        v_attributes = [j.split(&#39;:&#39;)[0] for i in filter(
            None, (v_in_feats, v_out_labels, v_extra_feats)) for j in i.split(&#39;,&#39;)]
        self.v_in_feats = v_in_feats
        self.v_out_labels = v_out_labels
        self.v_extra_feats = v_extra_feats
        # If batch_size is given, calculate the number of batches
        if batch_size:
            self.batch_size = batch_size
            self.num_batches = math.ceil(
                self._graph.number_of_vertices(filter_by=filter_by)/batch_size)
        else:
            self.num_batches = num_batches
            self.batch_size = math.ceil(
                self._graph.number_of_vertices(filter_by=filter_by)/num_batches)
        # Initialize temp ID for every vertex
        self._payload[&#34;tmp_id&#34;] = tmp_id
        resp = self._graph._mixed_session.get(
            self._base_endpoint + &#34;/shuffle/vertices/init&#34;, params=self._payload)
        resp.raise_for_status()
        self.shuffle = shuffle
        # Initialize the sampler
        self._base_endpoint += &#34;/sample/neighbor&#34;
        self._payload[&#34;v_attributes&#34;] = &#39;,&#39;.join(v_attributes)
        self._payload[&#34;num_neighbors&#34;] = num_neighbors
        self._payload[&#34;num_hops&#34;] = num_hops
        self._payload[&#34;filter_by&#34;] = filter_by
        resp = self._graph._mixed_session.get(
            self._base_endpoint+&#34;/init&#34;, params=self._payload)
        resp.raise_for_status()

    def start_requester(self, out_q: Queue) -&gt; None:
        args = (self._exit_event,
                self._request_task_q,
                out_q,
                self._base_endpoint+&#34;/run&#34;,
                self._payload,
                self._graph,
                {&#34;cloud-keys&#34;: self._cloud_keys},
                True)
        self._requester = Thread(target=self._request, args=args)
        self._requester.start()

    def start_reader(self) -&gt; None:
        self._reader = Thread(target=self._read_file,
                              args=(self._exit_event,
                                    self._read_task_q,
                                    self._data_q,
                                    self.output_format,
                                    self.v_in_feats,
                                    self.v_out_labels,
                                    self.v_extra_feats,
                                    True))
        self._reader.start()

    def __iter__(self):
        if self.num_batches == 1:
            return iter([self.data])
        if self._iterations == 0 or self.shuffle:
            resp = self._graph._rest_session.get(
                &#34;{}:8000/shuffle/vertices/run&#34;.format(self._graph.host), params=self._payload)
            resp.raise_for_status()
        self.reset()
        self.start()
        self._iterations += 1
        self._payload[&#34;iterations&#34;] = self._iterations
        return self</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tgml.dataloaders.EdgeLoader"><code class="flex name class">
<span>class <span class="ident">EdgeLoader</span></span>
<span>(</span><span>graph:<a title="tgml.data.TigerGraph" href="data.html#tgml.data.TigerGraph">TigerGraph</a>, batch_size:int=None, num_batches:int=1, local_storage_path:str='./tmp', cloud_storage_path:str=None, buffer_size:int=4, output_format:str='dataframe', cache_id:str=None, aws_access_key_id:str=None, aws_secret_access_key:str=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Data loader that pulls either the whole edgelist or batches of edges from database.
Edge attributes are not supported.</p>
<p><strong>Note</strong>: For the first time you initialize the loader on a graph in TigerGraph,
the initialization might take half a minute as it installs the corresponding
query to the database and optimizes it. However, the query installation only
needs to be done once, so it will take no time when you initialize the loader
on the same TG graph again. For the data loader to work, the <em>Graph Data Processing Service</em>
has to be running on the TigerGraph server.</p>
<p>There are two ways to use the data loader. See <a href="https://github.com/tg-bill/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb">here</a> for examples.</p>
<ul>
<li>First, it can be used as an iterator, which means you can loop through
it to get every batch of data. If you load all edges at once (<code>num_batches=1</code>),
there will be only one batch (of all the edges) in the iterator.</li>
<li>Second, you can access the <code>data</code> property of the class directly. If there is
only one batch of data to load, it will give you the batch directly instead
of an iterator, which might make more sense in that case. If there are
multiple batches of data to load, it will return the loader again.</li>
</ul>
<p>It can either stream data directly from the server or cache data on the cloud.
Set <code>cloud_storage_path</code> to turn on cloud cache. This way data will be moved to
a cloud storage first and then downloaded
to local, so it will be slower compared to streaming directly from the server.
However, when there are multiple consumers of the same data such as when trying
out different models in parallel or tuning hyperparameters, the cloud caching
would reduce workload of the server, and consequently it might be faster overall.
If using cloud caching, cloud storage access keys need to be provided. For AWS s3,
<code>aws_access_key_id</code> and <code>aws_secret_access_key</code> are required. However, the class can
read from environment variables <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>,
and again it is recommended to store those credentials in the <code>.env</code> file instead of hardcoding them. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>graph</code></strong> :&ensp;<code>TigerGraph</code></dt>
<dd>Connection to the TigerGraph database.</dd>
<dt><strong><code>batch_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Size of each batch. If given, <code>num_batches</code>
will be recalculated based on batch size. Defaults to None.</dd>
<dt><strong><code>num_batches</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of batches to split the whole dataset.
Defaults to 1.</dd>
<dt><strong><code>local_storage_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Place to store data locally.
Defaults to "./tmp".</dd>
<dt><strong><code>cloud_storage_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>S3 path used for cloud caching. If not None, cloud caching will be used.
Defaults to None.</dd>
<dt><strong><code>buffer_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of data batches to prefetch and store
in memory. Defaults to 4.</dd>
<dt><strong><code>output_format</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Format of the output data of the loader.
Only pandas dataframe is supported. Defaults to "dataframe".</dd>
<dt><strong><code>cache_id</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>An identifier associated to data from this loader. If none, a random string will be used automatically. Defaults to None.</dd>
<dt><strong><code>aws_access_key_id</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>AWS access key for cloud storage. Defaults to None.</dd>
<dt><strong><code>aws_secret_access_key</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>AWS access key secret for cloud storage. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EdgeLoader(BaseLoader):
    def __init__(self,
                 graph: TigerGraph,
                 batch_size: int = None,
                 num_batches: int = 1,
                 local_storage_path: str = &#34;./tmp&#34;,
                 cloud_storage_path: str = None,
                 buffer_size: int = 4,
                 output_format: str = &#34;dataframe&#34;,
                 cache_id: str = None,
                 aws_access_key_id: str = None,
                 aws_secret_access_key: str = None) -&gt; None:
        &#34;&#34;&#34;Data loader that pulls either the whole edgelist or batches of edges from database. 
        Edge attributes are not supported.

        **Note**: For the first time you initialize the loader on a graph in TigerGraph, 
        the initialization might take half a minute as it installs the corresponding 
        query to the database and optimizes it. However, the query installation only 
        needs to be done once, so it will take no time when you initialize the loader 
        on the same TG graph again. For the data loader to work, the *Graph Data Processing Service* 
        has to be running on the TigerGraph server.

        There are two ways to use the data loader. See [here](https://github.com/tg-bill/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb) for examples.

        * First, it can be used as an iterator, which means you can loop through 
          it to get every batch of data. If you load all edges at once (`num_batches=1`), 
          there will be only one batch (of all the edges) in the iterator.
        * Second, you can access the `data` property of the class directly. If there is 
          only one batch of data to load, it will give you the batch directly instead 
          of an iterator, which might make more sense in that case. If there are 
          multiple batches of data to load, it will return the loader again.

        It can either stream data directly from the server or cache data on the cloud. 
        Set `cloud_storage_path` to turn on cloud cache. This way data will be moved to 
        a cloud storage first and then downloaded 
        to local, so it will be slower compared to streaming directly from the server. 
        However, when there are multiple consumers of the same data such as when trying 
        out different models in parallel or tuning hyperparameters, the cloud caching 
        would reduce workload of the server, and consequently it might be faster overall. 
        If using cloud caching, cloud storage access keys need to be provided. For AWS s3, 
        `aws_access_key_id` and `aws_secret_access_key` are required. However, the class can 
        read from environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`, 
        and again it is recommended to store those credentials in the `.env` file instead of hardcoding them. 

        Args:
            graph (TigerGraph): Connection to the TigerGraph database.
            batch_size (int, optional): Size of each batch. If given, `num_batches` 
                will be recalculated based on batch size. Defaults to None.
            num_batches (int, optional): Number of batches to split the whole dataset. 
                Defaults to 1.
            local_storage_path (str, optional): Place to store data locally. 
                Defaults to &#34;./tmp&#34;.
            cloud_storage_path (str, optional): S3 path used for cloud caching. If not None, cloud caching will be used.
                Defaults to None.
            buffer_size (int, optional): Number of data batches to prefetch and store 
                in memory. Defaults to 4.
            output_format (str, optional): Format of the output data of the loader. 
                Only pandas dataframe is supported. Defaults to &#34;dataframe&#34;.
            cache_id (str, optional): An identifier associated to data from this loader. If none, a random string will be used automatically. Defaults to None.
            aws_access_key_id (str, optional): AWS access key for cloud storage. Defaults to None.
            aws_secret_access_key (str, optional): AWS access key secret for cloud storage. Defaults to None.
        &#34;&#34;&#34;
        super().__init__(graph, local_storage_path, cloud_storage_path,
                         buffer_size, output_format, num_batches, cache_id,
                         aws_access_key_id, aws_secret_access_key)
        # If batch_size is given, calculate the number of batches
        if batch_size:
            self.batch_size = batch_size
            self.num_batches = math.ceil(
                self._graph.number_of_edges()/batch_size)
        else:
            self.num_batches = num_batches
            self.batch_size = math.ceil(
                self._graph.number_of_edges()/num_batches)
        # Initialize the exporter
        self._base_endpoint += &#34;/export/edges&#34;
        self._payload[&#34;num_batches&#34;] = self.num_batches
        self._graph._mixed_session.get(
            self._base_endpoint+&#34;/init&#34;, params=self._payload)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tgml.dataloaders.BaseLoader</li>
</ul>
</dd>
<dt id="tgml.dataloaders.GraphLoader"><code class="flex name class">
<span>class <span class="ident">GraphLoader</span></span>
<span>(</span><span>graph:<a title="tgml.data.TigerGraph" href="data.html#tgml.data.TigerGraph">TigerGraph</a>, v_in_feats:str='', v_out_labels:str='', v_extra_feats:str='', local_storage_path:str='./tmp', cloud_storage_path:str=None, buffer_size:int=4, output_format:str='PyG', num_batches:int=1, cache_id:str=None, reindex:bool=False, aws_access_key_id:str=None, aws_secret_access_key:str=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Data loader that pulls the whole graph from database. </p>
<p><strong>Note</strong>: For the first time you initialize the loader on a graph in TigerGraph,
the initialization might take half a minute as it installs the corresponding
query to the database and optimizes it. However, the query installation only
needs to be done once, so it will take no time when you initialize the loader
on the same TG graph again. For the data loader to work, the <em>Graph Data Processing Service</em>
has to be running on the TigerGraph server.</p>
<p>There are two ways to use the data loader. See <a href="https://github.com/tg-bill/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb">here</a> for examples.</p>
<ul>
<li>First, it can be used as an iterator, which means you can loop through it to get every batch of data. Since this loader loads the whole graph at once, there will be only one batch of data (of the whole graph) in the iterator.</li>
<li>Second, you can access the <code>data</code> property of the class directly. Since there is only one batch of data (the whole graph), it will give you the batch directly instead of an iterator.</li>
</ul>
<p>It can either stream data directly from the server or cache data on the cloud.
Set <code>cloud_storage_path</code> to turn on cloud cache. This way data will be moved to
a cloud storage first and then downloaded
to local, so it will be slower compared to streaming directly from the server.
However, when there are multiple consumers of the same data such as when trying
out different models in parallel or tuning hyperparameters, the cloud caching
would reduce workload of the server, and consequently it might be faster overall.
If using cloud caching, cloud storage access keys need to be provided. For AWS s3,
<code>aws_access_key_id</code> and <code>aws_secret_access_key</code> are required. However, the class
can read from environment variables <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>,
and hence it is recommended to store those credentials in the <code>.env</code> file instead of hardcoding them. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>graph</code></strong> :&ensp;<code>TigerGraph</code></dt>
<dd>Connection to the TigerGraph database.</dd>
<dt><strong><code>v_in_feats</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Attributes to be used as input features and their types. Attributes should be seperated by ',' and an attribute and its type should be separated by ':'. The type of an attrbiute can be omitted together with the separator ':', and the attribute will be default to type "float32". Defaults to "".</dd>
<dt><strong><code>v_out_labels</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Attributes to be used as labels for prediction. It follows the same format as 'v_in_feats'. Defaults to "".</dd>
<dt><strong><code>v_extra_feats</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Other attributes to get such as indicators of train/test data. It follows the same format as 'v_in_feats'. Defaults to "".</dd>
<dt><strong><code>local_storage_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Place to store data locally.
Defaults to "./tmp".</dd>
<dt><strong><code>cloud_storage_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>S3 path used for cloud caching. If not None, cloud caching will be used.
Defaults to None.</dd>
<dt><strong><code>buffer_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of data batches to prefetch and store
in memory. Defaults to 4.</dd>
<dt><strong><code>output_format</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Format of the output data of the loader. Only
"PyG" is supported. Defaults to "PyG".</dd>
<dt><strong><code>reindex</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to reindex the vertices. Defaults to False.</dd>
<dt><strong><code>cache_id</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>An identifier associated to data from this loader. If none, a random string will be used automatically. Defaults to None.</dd>
<dt><strong><code>aws_access_key_id</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>AWS access key for cloud storage. Defaults to None.</dd>
<dt><strong><code>aws_secret_access_key</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>AWS access key secret for cloud storage. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GraphLoader(BaseLoader):
    def __init__(self,
                 graph: TigerGraph,
                 v_in_feats: str = &#34;&#34;,
                 v_out_labels: str = &#34;&#34;,
                 v_extra_feats: str = &#34;&#34;,
                 local_storage_path: str = &#34;./tmp&#34;,
                 cloud_storage_path: str = None,
                 buffer_size: int = 4,
                 output_format: str = &#34;PyG&#34;,
                 num_batches: int = 1,
                 cache_id: str = None,
                 reindex: bool = False,
                 aws_access_key_id: str = None,
                 aws_secret_access_key: str = None) -&gt; None:
        &#34;&#34;&#34;Data loader that pulls the whole graph from database. 

        **Note**: For the first time you initialize the loader on a graph in TigerGraph, 
        the initialization might take half a minute as it installs the corresponding 
        query to the database and optimizes it. However, the query installation only 
        needs to be done once, so it will take no time when you initialize the loader 
        on the same TG graph again. For the data loader to work, the *Graph Data Processing Service* 
        has to be running on the TigerGraph server.

        There are two ways to use the data loader. See [here](https://github.com/tg-bill/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb) for examples.

        * First, it can be used as an iterator, which means you can loop through it to get every batch of data. Since this loader loads the whole graph at once, there will be only one batch of data (of the whole graph) in the iterator.
        * Second, you can access the `data` property of the class directly. Since there is only one batch of data (the whole graph), it will give you the batch directly instead of an iterator.

        It can either stream data directly from the server or cache data on the cloud. 
        Set `cloud_storage_path` to turn on cloud cache. This way data will be moved to 
        a cloud storage first and then downloaded 
        to local, so it will be slower compared to streaming directly from the server. 
        However, when there are multiple consumers of the same data such as when trying 
        out different models in parallel or tuning hyperparameters, the cloud caching 
        would reduce workload of the server, and consequently it might be faster overall. 
        If using cloud caching, cloud storage access keys need to be provided. For AWS s3, 
        `aws_access_key_id` and `aws_secret_access_key` are required. However, the class 
        can read from environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`, 
        and hence it is recommended to store those credentials in the `.env` file instead of hardcoding them. 

        Args:
            graph (TigerGraph): Connection to the TigerGraph database.
            v_in_feats (str, optional): Attributes to be used as input features and their types. Attributes should be seperated by &#39;,&#39; and an attribute and its type should be separated by &#39;:&#39;. The type of an attrbiute can be omitted together with the separator &#39;:&#39;, and the attribute will be default to type &#34;float32&#34;. Defaults to &#34;&#34;.
            v_out_labels (str, optional): Attributes to be used as labels for prediction. It follows the same format as &#39;v_in_feats&#39;. Defaults to &#34;&#34;.
            v_extra_feats (str, optional): Other attributes to get such as indicators of train/test data. It follows the same format as &#39;v_in_feats&#39;. Defaults to &#34;&#34;.
            local_storage_path (str, optional): Place to store data locally. 
                Defaults to &#34;./tmp&#34;.
            cloud_storage_path (str, optional): S3 path used for cloud caching. If not None, cloud caching will be used.
                Defaults to None.
            buffer_size (int, optional): Number of data batches to prefetch and store 
                in memory. Defaults to 4.
            output_format (str, optional): Format of the output data of the loader. Only
                &#34;PyG&#34; is supported. Defaults to &#34;PyG&#34;.
            reindex (bool, optional): Whether to reindex the vertices. Defaults to False.
            cache_id (str, optional): An identifier associated to data from this loader. If none, a random string will be used automatically. Defaults to None.
            aws_access_key_id (str, optional): AWS access key for cloud storage. Defaults to None.
            aws_secret_access_key (str, optional): AWS access key secret for cloud storage. Defaults to None.
        &#34;&#34;&#34;
        super().__init__(graph, local_storage_path, cloud_storage_path,
                         buffer_size, output_format, num_batches, cache_id,
                         aws_access_key_id, aws_secret_access_key)
        self.reindex = reindex
        # Resolve attributes
        v_attributes = [j.split(&#39;:&#39;)[0] for i in filter(
            None, (v_in_feats, v_out_labels, v_extra_feats)) for j in i.split(&#39;,&#39;)]
        self.v_in_feats = v_in_feats
        self.v_out_labels = v_out_labels
        self.v_extra_feats = v_extra_feats
        # Initialize the exporter
        self._base_endpoint += &#34;/export/graph&#34;
        self._payload[&#34;v_attributes&#34;] = &#39;,&#39;.join(v_attributes)
        resp = self._graph._mixed_session.get(
            self._base_endpoint+&#34;/init&#34;, params=self._payload)
        resp.raise_for_status()

    def start_requester(self, out_q: Queue) -&gt; None:
        args = (self._exit_event,
                self._request_task_q,
                out_q,
                self._base_endpoint+&#34;/run&#34;,
                self._payload,
                self._graph,
                {&#34;cloud-keys&#34;: self._cloud_keys},
                True)
        self._requester = Thread(target=self._request, args=args)
        self._requester.start()

    def start_reader(self) -&gt; None:
        self._reader = Thread(target=self._read_file,
                              args=(self._exit_event,
                                    self._read_task_q,
                                    self._data_q,
                                    self.output_format,
                                    self.v_in_feats,
                                    self.v_out_labels,
                                    self.v_extra_feats,
                                    self.reindex))
        self._reader.start()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tgml.dataloaders.BaseLoader</li>
</ul>
</dd>
<dt id="tgml.dataloaders.NeighborLoader"><code class="flex name class">
<span>class <span class="ident">NeighborLoader</span></span>
<span>(</span><span>graph:<a title="tgml.data.TigerGraph" href="data.html#tgml.data.TigerGraph">TigerGraph</a>, tmp_id:str='tmp_id', v_in_feats:str='', v_out_labels:str='', v_extra_feats:str='', local_storage_path:str='./tmp', cloud_storage_path:str=None, buffer_size:int=4, output_format:str='PyG', batch_size:int=None, num_batches:int=1, num_neighbors:int=10, num_hops:int=2, cache_id:str=None, shuffle:bool=False, filter_by:str=None, aws_access_key_id:str=None, aws_secret_access_key:str=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A data loader that performs neighbor sampling as introduced in the
<a href="https://arxiv.org/abs/1706.02216">Inductive Representation Learning on Large Graphs</a> paper. </p>
<p>Specifically, it first chooses <code>batch_size</code> number of vertices as seeds,
then picks <code>num_neighbors</code> number of neighbors of each seed at random,
then <code>num_neighbors</code> neighbors of each neighbor, and repeat for <code>num_hops</code>.
This generates one subgraph. As you loop through this data loader, all
vertices will be chosen as seeds and you will get all subgraphs expanded from those seeds.</p>
<p>If you want to limit seeds to certain vertices, the boolean attribute provided to <code>filter_by</code> will be used to indicate which vertices can be included as seeds.</p>
<p><strong>Note</strong>: For the first time you initialize the loader on a graph in TigerGraph,
the initialization might take half a minute as it installs the corresponding
query to the database and optimizes it. However, the query installation only
needs to be done once, so it will take no time when you initialize the loader
on the same TG graph again. For the data loader to work, the <em>Graph Data Processing Service</em>
has to be running on the TigerGraph server.</p>
<p>There are two ways to use the data loader. See <a href="https://github.com/tg-bill/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb">here</a> for examples.</p>
<ul>
<li>First, it can be used as an iterator, which means you can loop through
it to get every batch of data. If you load all edges at once (<code>num_batches=1</code>),
there will be only one batch (of all the edges) in the iterator.</li>
<li>Second, you can access the <code>data</code> property of the class directly. If there is
only one batch of data to load, it will give you the batch directly instead
of an iterator, which might make more sense in that case. If there are
multiple batches of data to load, it will return the loader again.</li>
</ul>
<p>It can either stream data directly from the server or cache data on the cloud.
Set <code>cloud_storage_path</code> to turn on cloud cache. This way data will be moved to
a cloud storage first and then downloaded
to local, so it will be slower compared to streaming directly from the server.
However, when there are multiple consumers of the same data such as when trying
out different models in parallel or tuning hyperparameters, the cloud caching
would reduce workload of the server, and consequently it might be faster overall.
If using cloud caching, cloud storage access keys need to be provided. For AWS s3,
<code>aws_access_key_id</code> and <code>aws_secret_access_key</code> are required. However, the class
can read from environment variables <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>,
and hence it is recommended to store those credentials in the <code>.env</code> file instead of hardcoding them. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>graph</code></strong> :&ensp;<code>TigerGraph</code></dt>
<dd>Connection to the TigerGraph database.</dd>
<dt><strong><code>tmp_id</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Attribute name that holds the temporary ID of
vertices. Defaults to "tmp_id".</dd>
<dt><strong><code>v_in_feats</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Attributes to be used as input features and their types. Attributes should be seperated by ',' and an attribute and its type should be separated by ':'. The type of an attrbiute can be omitted together with the separator ':', and the attribute will be default to type "float32". and Defaults to "".</dd>
<dt><strong><code>v_out_labels</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Attributes to be used as labels for prediction. It follows the same format as 'v_in_feats'. Defaults to "".</dd>
<dt><strong><code>v_extra_feats</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Other attributes to get such as indicators of train/test data. It follows the same format as 'v_in_feats'. Defaults to "".</dd>
<dt><strong><code>local_storage_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Place to store data locally.
Defaults to "./tmp".</dd>
<dt><strong><code>cloud_storage_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>S3 path used for cloud caching. If not None, cloud caching will be used.
Defaults to None.</dd>
<dt><strong><code>buffer_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of data batches to prefetch and store
in memory. Defaults to 4.</dd>
<dt><strong><code>output_format</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Format of the output data of the loader. Only
"PyG" is supported. Defaults to "PyG".</dd>
<dt><strong><code>batch_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of vertices as seeds in each batch.
Defaults to None.</dd>
<dt><strong><code>num_batches</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of batches to split the vertices.
Defaults to 1.</dd>
<dt><strong><code>num_neighbors</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of neighbors to sample for each vertex.
Defaults to 10.</dd>
<dt><strong><code>num_hops</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of hops to traverse when sampling neighbors.
Defaults to 2.</dd>
<dt><strong><code>shuffle</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to shuffle the vertices after every epoch.
Defaults to False.</dd>
<dt><strong><code>filter_by</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>A boolean attribute used to indicate which vertices
can be included as seeds. Defaults to None.</dd>
<dt><strong><code>cache_id</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>An identifier associated to data from this loader. If none, a random string will be used automatically. Defaults to None.</dd>
<dt><strong><code>aws_access_key_id</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>AWS access key for cloud storage. Defaults to None.</dd>
<dt><strong><code>aws_secret_access_key</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>AWS access key secret for cloud storage. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NeighborLoader(BaseLoader):
    def __init__(self,
                 graph: TigerGraph,
                 tmp_id: str = &#34;tmp_id&#34;,
                 v_in_feats: str = &#34;&#34;,
                 v_out_labels: str = &#34;&#34;,
                 v_extra_feats: str = &#34;&#34;,
                 local_storage_path: str = &#34;./tmp&#34;,
                 cloud_storage_path: str = None,
                 buffer_size: int = 4,
                 output_format: str = &#34;PyG&#34;,
                 batch_size: int = None,
                 num_batches: int = 1,
                 num_neighbors: int = 10,
                 num_hops: int = 2,
                 cache_id: str = None,
                 shuffle: bool = False,
                 filter_by: str = None,
                 aws_access_key_id: str = None,
                 aws_secret_access_key: str = None) -&gt; None:
        &#34;&#34;&#34;A data loader that performs neighbor sampling as introduced in the 
        [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216) paper. 

        Specifically, it first chooses `batch_size` number of vertices as seeds, 
        then picks `num_neighbors` number of neighbors of each seed at random, 
        then `num_neighbors` neighbors of each neighbor, and repeat for `num_hops`. 
        This generates one subgraph. As you loop through this data loader, all 
        vertices will be chosen as seeds and you will get all subgraphs expanded from those seeds.

        If you want to limit seeds to certain vertices, the boolean attribute provided to `filter_by` will be used to indicate which vertices can be included as seeds.

        **Note**: For the first time you initialize the loader on a graph in TigerGraph, 
        the initialization might take half a minute as it installs the corresponding 
        query to the database and optimizes it. However, the query installation only 
        needs to be done once, so it will take no time when you initialize the loader 
        on the same TG graph again. For the data loader to work, the *Graph Data Processing Service* 
        has to be running on the TigerGraph server.

        There are two ways to use the data loader. See [here](https://github.com/tg-bill/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb) for examples.

        * First, it can be used as an iterator, which means you can loop through 
          it to get every batch of data. If you load all edges at once (`num_batches=1`), 
          there will be only one batch (of all the edges) in the iterator.
        * Second, you can access the `data` property of the class directly. If there is 
          only one batch of data to load, it will give you the batch directly instead 
          of an iterator, which might make more sense in that case. If there are 
          multiple batches of data to load, it will return the loader again.

        It can either stream data directly from the server or cache data on the cloud. 
        Set `cloud_storage_path` to turn on cloud cache. This way data will be moved to 
        a cloud storage first and then downloaded 
        to local, so it will be slower compared to streaming directly from the server. 
        However, when there are multiple consumers of the same data such as when trying 
        out different models in parallel or tuning hyperparameters, the cloud caching 
        would reduce workload of the server, and consequently it might be faster overall. 
        If using cloud caching, cloud storage access keys need to be provided. For AWS s3, 
        `aws_access_key_id` and `aws_secret_access_key` are required. However, the class 
        can read from environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`, 
        and hence it is recommended to store those credentials in the `.env` file instead of hardcoding them. 

        Args:
            graph (TigerGraph): Connection to the TigerGraph database.
            tmp_id (str, optional): Attribute name that holds the temporary ID of 
                vertices. Defaults to &#34;tmp_id&#34;.
            v_in_feats (str, optional): Attributes to be used as input features and their types. Attributes should be seperated by &#39;,&#39; and an attribute and its type should be separated by &#39;:&#39;. The type of an attrbiute can be omitted together with the separator &#39;:&#39;, and the attribute will be default to type &#34;float32&#34;. and Defaults to &#34;&#34;.
            v_out_labels (str, optional): Attributes to be used as labels for prediction. It follows the same format as &#39;v_in_feats&#39;. Defaults to &#34;&#34;.
            v_extra_feats (str, optional): Other attributes to get such as indicators of train/test data. It follows the same format as &#39;v_in_feats&#39;. Defaults to &#34;&#34;.
            local_storage_path (str, optional): Place to store data locally. 
                Defaults to &#34;./tmp&#34;.
            cloud_storage_path (str, optional): S3 path used for cloud caching. If not None, cloud caching will be used.
                Defaults to None.
            buffer_size (int, optional): Number of data batches to prefetch and store 
                in memory. Defaults to 4.
            output_format (str, optional): Format of the output data of the loader. Only
                &#34;PyG&#34; is supported. Defaults to &#34;PyG&#34;.
            batch_size (int, optional): Number of vertices as seeds in each batch. 
                Defaults to None.
            num_batches (int, optional): Number of batches to split the vertices. 
                Defaults to 1.
            num_neighbors (int, optional): Number of neighbors to sample for each vertex. 
                Defaults to 10.
            num_hops (int, optional): Number of hops to traverse when sampling neighbors. 
                Defaults to 2.
            shuffle (bool, optional): Whether to shuffle the vertices after every epoch. 
                Defaults to False.
            filter_by (str, optional): A boolean attribute used to indicate which vertices 
                can be included as seeds. Defaults to None.
            cache_id (str, optional): An identifier associated to data from this loader. If none, a random string will be used automatically. Defaults to None.
            aws_access_key_id (str, optional): AWS access key for cloud storage. Defaults to None.
            aws_secret_access_key (str, optional): AWS access key secret for cloud storage. Defaults to None.
        &#34;&#34;&#34;
        super().__init__(graph, local_storage_path, cloud_storage_path,
                         buffer_size, output_format, num_batches, cache_id,
                         aws_access_key_id, aws_secret_access_key)
        # Resolve attributes
        v_attributes = [j.split(&#39;:&#39;)[0] for i in filter(
            None, (v_in_feats, v_out_labels, v_extra_feats)) for j in i.split(&#39;,&#39;)]
        self.v_in_feats = v_in_feats
        self.v_out_labels = v_out_labels
        self.v_extra_feats = v_extra_feats
        # If batch_size is given, calculate the number of batches
        if batch_size:
            self.batch_size = batch_size
            self.num_batches = math.ceil(
                self._graph.number_of_vertices(filter_by=filter_by)/batch_size)
        else:
            self.num_batches = num_batches
            self.batch_size = math.ceil(
                self._graph.number_of_vertices(filter_by=filter_by)/num_batches)
        # Initialize temp ID for every vertex
        self._payload[&#34;tmp_id&#34;] = tmp_id
        resp = self._graph._mixed_session.get(
            self._base_endpoint + &#34;/shuffle/vertices/init&#34;, params=self._payload)
        resp.raise_for_status()
        self.shuffle = shuffle
        # Initialize the sampler
        self._base_endpoint += &#34;/sample/neighbor&#34;
        self._payload[&#34;v_attributes&#34;] = &#39;,&#39;.join(v_attributes)
        self._payload[&#34;num_neighbors&#34;] = num_neighbors
        self._payload[&#34;num_hops&#34;] = num_hops
        self._payload[&#34;filter_by&#34;] = filter_by
        resp = self._graph._mixed_session.get(
            self._base_endpoint+&#34;/init&#34;, params=self._payload)
        resp.raise_for_status()

    def start_requester(self, out_q: Queue) -&gt; None:
        args = (self._exit_event,
                self._request_task_q,
                out_q,
                self._base_endpoint+&#34;/run&#34;,
                self._payload,
                self._graph,
                {&#34;cloud-keys&#34;: self._cloud_keys},
                True)
        self._requester = Thread(target=self._request, args=args)
        self._requester.start()

    def start_reader(self) -&gt; None:
        self._reader = Thread(target=self._read_file,
                              args=(self._exit_event,
                                    self._read_task_q,
                                    self._data_q,
                                    self.output_format,
                                    self.v_in_feats,
                                    self.v_out_labels,
                                    self.v_extra_feats,
                                    True))
        self._reader.start()

    def __iter__(self):
        if self.num_batches == 1:
            return iter([self.data])
        if self._iterations == 0 or self.shuffle:
            resp = self._graph._rest_session.get(
                &#34;{}:8000/shuffle/vertices/run&#34;.format(self._graph.host), params=self._payload)
            resp.raise_for_status()
        self.reset()
        self.start()
        self._iterations += 1
        self._payload[&#34;iterations&#34;] = self._iterations
        return self</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tgml.dataloaders.BaseLoader</li>
</ul>
</dd>
<dt id="tgml.dataloaders.VertexLoader"><code class="flex name class">
<span>class <span class="ident">VertexLoader</span></span>
<span>(</span><span>graph:<a title="tgml.data.TigerGraph" href="data.html#tgml.data.TigerGraph">TigerGraph</a>, batch_size:int=None, num_batches:int=1, attributes:str='', local_storage_path:str='./tmp', cloud_storage_path:str=None, buffer_size:int=4, output_format:str='dataframe', cache_id:str=None, aws_access_key_id:str=None, aws_secret_access_key:str=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Data loader that pulls either all the vertices or batches of vertices from database. </p>
<p><strong>Note</strong>: For the first time you initialize the loader on a graph in TigerGraph,
the initialization might take half a minute as it installs the corresponding
query to the database and optimizes it. However, the query installation only
needs to be done once, so it will take no time when you initialize the loader
on the same TG graph again. For the data loader to work, the <em>Graph Data Processing Service</em>
has to be running on the TigerGraph server.</p>
<p>There are two ways to use the data loader.</p>
<ul>
<li>First, it can be used as an iterator, which means you can loop through
it to get every batch of data. If you load all vertices at once (<code>num_batches=1</code>),
there will be only one batch (of all the vertices) in the iterator.</li>
<li>Second, you can access the <code>data</code> property of the class directly. If there is
only one batch of data to load, it will give you the batch directly instead
of an iterator, which might make more sense in that case. If there are
multiple batches of data to load, it will return the loader again.</li>
</ul>
<p>It can either stream data directly from the server or cache data on the cloud.
Set <code>cloud_storage_path</code> to turn on cloud cache. This way data will be moved to
a cloud storage first and then downloaded
to local, so it will be slower compared to streaming directly from the server.
However, when there are multiple consumers of the same data such as when trying
out different models in parallel or tuning hyperparameters, the cloud caching
would reduce workload of the server, and consequently it might be faster overall.
If using cloud caching, cloud storage access keys need to be provided. For AWS s3,
<code>aws_access_key_id</code> and <code>aws_secret_access_key</code> are required. However, the class
can read from environment variables <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>,
and hence it is recommended to store those credentials in the <code>.env</code> file instead of hardcoding them.
</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>graph</code></strong> :&ensp;<code>TigerGraph</code></dt>
<dd>Connection to the TigerGraph database.</dd>
<dt><strong><code>batch_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Size of each batch. If given, <code>num_batches</code>
will be recalculated based on batch size. Defaults to None.</dd>
<dt><strong><code>num_batches</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of batches to split the whole dataset.
Defaults to 1.</dd>
<dt><strong><code>attributes</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Vertex attributes to get, separated by comma.
Defaults to "".</dd>
<dt><strong><code>local_storage_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Place to store data locally.
Defaults to "./tmp".</dd>
<dt><strong><code>cloud_storage_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>S3 path used for cloud caching. If not None, cloud caching will be used.
Defaults to None.</dd>
<dt><strong><code>buffer_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of data batches to prefetch and store
in memory. Defaults to 4.</dd>
<dt><strong><code>output_format</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Format of the output data of the loader.
Only pandas dataframe is supported. Defaults to "dataframe".</dd>
<dt><strong><code>cache_id</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>An identifier associated to data from this loader. If none, a random string will be used automatically. Defaults to None.</dd>
<dt><strong><code>aws_access_key_id</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>AWS access key for cloud storage. Defaults to None.</dd>
<dt><strong><code>aws_secret_access_key</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>AWS access key secret for cloud storage. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class VertexLoader(BaseLoader):
    def __init__(self,
                 graph: TigerGraph,
                 batch_size: int = None,
                 num_batches: int = 1,
                 attributes: str = &#34;&#34;,
                 local_storage_path: str = &#34;./tmp&#34;,
                 cloud_storage_path: str = None,
                 buffer_size: int = 4,
                 output_format: str = &#34;dataframe&#34;,
                 cache_id: str = None,
                 aws_access_key_id: str = None,
                 aws_secret_access_key: str = None) -&gt; None:
        &#34;&#34;&#34;Data loader that pulls either all the vertices or batches of vertices from database. 

        **Note**: For the first time you initialize the loader on a graph in TigerGraph, 
        the initialization might take half a minute as it installs the corresponding 
        query to the database and optimizes it. However, the query installation only 
        needs to be done once, so it will take no time when you initialize the loader 
        on the same TG graph again. For the data loader to work, the *Graph Data Processing Service* 
        has to be running on the TigerGraph server.

        There are two ways to use the data loader.

        * First, it can be used as an iterator, which means you can loop through 
          it to get every batch of data. If you load all vertices at once (`num_batches=1`), 
          there will be only one batch (of all the vertices) in the iterator.
        * Second, you can access the `data` property of the class directly. If there is 
          only one batch of data to load, it will give you the batch directly instead 
          of an iterator, which might make more sense in that case. If there are 
          multiple batches of data to load, it will return the loader again.

        It can either stream data directly from the server or cache data on the cloud. 
        Set `cloud_storage_path` to turn on cloud cache. This way data will be moved to 
        a cloud storage first and then downloaded 
        to local, so it will be slower compared to streaming directly from the server. 
        However, when there are multiple consumers of the same data such as when trying 
        out different models in parallel or tuning hyperparameters, the cloud caching 
        would reduce workload of the server, and consequently it might be faster overall. 
        If using cloud caching, cloud storage access keys need to be provided. For AWS s3, 
        `aws_access_key_id` and `aws_secret_access_key` are required. However, the class 
        can read from environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`, 
        and hence it is recommended to store those credentials in the `.env` file instead of hardcoding them.  

        Args:
            graph (TigerGraph): Connection to the TigerGraph database.
            batch_size (int, optional): Size of each batch. If given, `num_batches` 
                will be recalculated based on batch size. Defaults to None.
            num_batches (int, optional): Number of batches to split the whole dataset. 
                Defaults to 1.
            attributes (str, optional): Vertex attributes to get, separated by comma. 
                Defaults to &#34;&#34;.
            local_storage_path (str, optional): Place to store data locally. 
                Defaults to &#34;./tmp&#34;.
            cloud_storage_path (str, optional): S3 path used for cloud caching. If not None, cloud caching will be used.
                Defaults to None.
            buffer_size (int, optional): Number of data batches to prefetch and store 
                in memory. Defaults to 4.
            output_format (str, optional): Format of the output data of the loader. 
                Only pandas dataframe is supported. Defaults to &#34;dataframe&#34;.
            cache_id (str, optional): An identifier associated to data from this loader. If none, a random string will be used automatically. Defaults to None.
            aws_access_key_id (str, optional): AWS access key for cloud storage. Defaults to None.
            aws_secret_access_key (str, optional): AWS access key secret for cloud storage. Defaults to None.
        &#34;&#34;&#34;
        super().__init__(graph, local_storage_path, cloud_storage_path,
                         buffer_size, output_format, num_batches, cache_id,
                         aws_access_key_id, aws_secret_access_key)
        self.attributes = attributes
        # If batch_size is given, calculate the number of batches
        if batch_size:
            self.batch_size = batch_size
            self.num_batches = math.ceil(
                self._graph.number_of_vertices()/batch_size)
        else:
            self.num_batches = num_batches
            self.batch_size = math.ceil(
                self._graph.number_of_vertices()/num_batches)
        # Initialize the exporter
        self._base_endpoint += &#34;/export/vertices&#34;
        self._payload[&#34;num_batches&#34;] = self.num_batches
        self._payload[&#34;attributes&#34;] = attributes
        self._graph._mixed_session.get(
            self._base_endpoint+&#34;/init&#34;, params=self._payload)

    def start_reader(self) -&gt; None:
        self._reader = Thread(target=self._read_file,
                              args=(self._exit_event,
                                    self._read_task_q,
                                    self._data_q,
                                    self.output_format,
                                    self.attributes))
        self._reader.start()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tgml.dataloaders.BaseLoader</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tgml" href="index.html">tgml</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tgml.dataloaders.EdgeLoader" href="#tgml.dataloaders.EdgeLoader">EdgeLoader</a></code></h4>
</li>
<li>
<h4><code><a title="tgml.dataloaders.GraphLoader" href="#tgml.dataloaders.GraphLoader">GraphLoader</a></code></h4>
</li>
<li>
<h4><code><a title="tgml.dataloaders.NeighborLoader" href="#tgml.dataloaders.NeighborLoader">NeighborLoader</a></code></h4>
</li>
<li>
<h4><code><a title="tgml.dataloaders.VertexLoader" href="#tgml.dataloaders.VertexLoader">VertexLoader</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>